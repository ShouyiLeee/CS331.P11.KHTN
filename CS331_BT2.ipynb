{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VpR72sBh8MVg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AunQMmVjNRQJ",
    "outputId": "ec8dd96a-d134-428a-cc41-2b7653c9018d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOHJP8pWjkTN"
   },
   "source": [
    "# Yêu cầu 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Jf2zhNFLNpoA"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # self.depthwise_conv1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=57, groups=32)\n",
    "        self.depthwise_conv1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1, groups=32)  # Depthwise convolution\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.pointwise_conv1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, groups=64)\n",
    "        self.pointwise_conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, groups=128)\n",
    "        self.pointwise_conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding = 1, groups = 128)\n",
    "        self.pointwise_conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, groups=256)  # Depthwise convolution\n",
    "        self.pointwise_conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1, groups=256)\n",
    "        self.pointwise_conv6 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.five_conv = nn.ModuleList([\n",
    "        nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=1, groups=512),  # 3x3 Depthwise Conv\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=0)  # 1x1 Pointwise Conv\n",
    "            ) for _ in range(5)\n",
    "        ])\n",
    "\n",
    "        self.depthwise_conv7 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=1, groups=512)  # Depthwise convolution\n",
    "        self.pointwise_conv7 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv8 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, groups=1024)\n",
    "        self.pointwise_conv8 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=101)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv1(x))\n",
    "      x = self.upsample(x)\n",
    "      x = F.relu(self.pointwise_conv1(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv2(x))\n",
    "      x = F.relu(self.pointwise_conv2(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv3(x))\n",
    "      x = F.relu(self.pointwise_conv3(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv4(x))\n",
    "      x = F.relu(self.pointwise_conv4(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv5(x))\n",
    "      x = F.relu(self.pointwise_conv5(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv6(x))\n",
    "      x = F.relu(self.pointwise_conv6(x))\n",
    "\n",
    "      for conv in self.five_conv:\n",
    "            x = F.relu(conv(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv7(x))\n",
    "      x = F.relu(self.pointwise_conv7(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv8(x))\n",
    "      x = F.relu(self.pointwise_conv8(x))\n",
    "\n",
    "      x = self.avg_pool(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.fc(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vNHIKzv7eOl_"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "h88DIHn6eTkz"
   },
   "outputs": [],
   "source": [
    "#Data Preprocesing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3599HWFFfV_c",
    "outputId": "1ddf63a8-484c-43d0-d328-5ea408f01960"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp\n",
      "From (redirected): https://drive.usercontent.google.com/download?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp&confirm=t&uuid=7477523f-0b34-48c9-b9e1-d38b99d2c495\n",
      "To: /content/caltech101/101_ObjectCategories.tar.gz\n",
      "100%|██████████| 132M/132M [00:01<00:00, 121MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./caltech101/101_ObjectCategories.tar.gz to ./caltech101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=175kQy3UsZ0wUEHZjqkUDdNVssr7bgh_m\n",
      "From (redirected): https://drive.usercontent.google.com/download?id=175kQy3UsZ0wUEHZjqkUDdNVssr7bgh_m&confirm=t&uuid=f03ce377-8de0-4589-b487-4472a5622780\n",
      "To: /content/caltech101/Annotations.tar\n",
      "100%|██████████| 14.0M/14.0M [00:00<00:00, 64.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./caltech101/Annotations.tar to ./caltech101\n"
     ]
    }
   ],
   "source": [
    "# Load Caltech101 dataset\n",
    "data_path='./'\n",
    "dataset = datasets.Caltech101(data_path, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KyRhhlqifYV_"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size + test_size])\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(val_test_dataset, [val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "snO70l08dKEN"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha * (1 - pt) ** self.gamma * ce_loss) if self.alpha is not None else (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGnC7GqtoNjf"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork_1().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MLWpvM2rdwc-"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def training(opttimize = 'Adam', lossFunction = 'CrossEntropy'):\n",
    "  if opttimize == 'Adam' :\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  elif opttimize == 'SGD':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  if lossFunction == 'CrossEntropy':\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "  elif lossFunction == 'FocalLoss':\n",
    "    criterion = FocalLoss().to(device)\n",
    "  for epoch in range(num_epochs):\n",
    "      for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # Backward and optimize\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          if (i+1) % 100 == 0:\n",
    "              print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "  print(\"Training finished!\")\n",
    "\n",
    "  # Testing the model\n",
    "  model.eval() # Set the model to evaluation mode\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test accuracy of the model on the {total} test images: {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbjIAEeUeV3B",
    "outputId": "e8641d90-4b4b-4cb6-c567-96b7dd44df66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 101/163 [00:12<00:08,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/163], Loss: 4.1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:18<00:00,  8.94it/s]\n",
      " 63%|██████▎   | 102/163 [00:10<00:05, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/163], Loss: 3.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.50it/s]\n",
      " 62%|██████▏   | 101/163 [00:10<00:06, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/163], Loss: 4.3980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00,  9.93it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/163], Loss: 4.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.48it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:06, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/163], Loss: 4.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.52it/s]\n",
      " 62%|██████▏   | 101/163 [00:10<00:06, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/163], Loss: 4.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.45it/s]\n",
      " 63%|██████▎   | 102/163 [00:10<00:05, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/163], Loss: 4.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00,  9.99it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/163], Loss: 4.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.57it/s]\n",
      " 63%|██████▎   | 102/163 [00:10<00:06, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/163], Loss: 4.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.53it/s]\n",
      " 63%|██████▎   | 102/163 [00:10<00:05, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/163], Loss: 4.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n",
      "Test accuracy of the model on the 1736 test images: 10.023041474654377%\n"
     ]
    }
   ],
   "source": [
    "training('Adam', 'CrossEntropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKpSbQDcfiPZ",
    "outputId": "364767fd-b9c7-4727-a18a-ef7979e03172"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 101/163 [00:11<00:06,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/163], Loss: 4.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:17<00:00,  9.56it/s]\n",
      " 62%|██████▏   | 101/163 [00:10<00:05, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/163], Loss: 3.5339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00,  9.99it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:07,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/163], Loss: 4.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/163], Loss: 3.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.71it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:05, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/163], Loss: 4.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.73it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/163], Loss: 3.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00, 10.13it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/163], Loss: 4.1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.69it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:06,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/163], Loss: 4.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:05, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/163], Loss: 4.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:05, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/163], Loss: 3.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n",
      "Test accuracy of the model on the 1736 test images: 8.46774193548387%\n"
     ]
    }
   ],
   "source": [
    "training('Adam', 'FocalLoss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "up99BkqNfl6_",
    "outputId": "d7f09c4b-d591-4310-eb06-43df2c433426"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/163], Loss: 4.2066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.60it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:06,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/163], Loss: 4.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.62it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:06, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/163], Loss: 3.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.68it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/163], Loss: 4.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00, 10.10it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/163], Loss: 4.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.59it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:06,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/163], Loss: 3.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.59it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:06, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/163], Loss: 3.6853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.46it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/163], Loss: 4.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00, 10.06it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/163], Loss: 4.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.62it/s]\n",
      " 63%|██████▎   | 102/163 [00:10<00:06,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/163], Loss: 4.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n",
      "Test accuracy of the model on the 1736 test images: 8.46774193548387%\n"
     ]
    }
   ],
   "source": [
    "training('SGD', 'CrossEntropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQEEo5snfnw8",
    "outputId": "122c9883-218f-49b5-9e0b-dba726cce3f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/163], Loss: 4.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.61it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:08,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/163], Loss: 3.7681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.73it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:06, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/163], Loss: 3.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/163], Loss: 4.1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.54it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:05, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/163], Loss: 3.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.31it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:07,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/163], Loss: 4.0835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.77it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/163], Loss: 3.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.68it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/163], Loss: 3.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.69it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/163], Loss: 3.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00, 10.10it/s]\n",
      " 63%|██████▎   | 102/163 [00:08<00:05, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/163], Loss: 4.3177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n",
      "Test accuracy of the model on the 1736 test images: 8.46774193548387%\n"
     ]
    }
   ],
   "source": [
    "training('SGD', 'FocalLoss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrhhnJ6djuuO"
   },
   "source": [
    "# Yêu cầu 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "oGudJ26Sjw34"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "\n",
    "        self.depthwise_conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, groups=64)\n",
    "        self.pointwise_conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, groups=128)\n",
    "        self.pointwise_conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding = 1, groups = 128)\n",
    "        self.pointwise_conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, groups=256)  # Depthwise convolution\n",
    "        self.pointwise_conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1, groups=256)\n",
    "        self.pointwise_conv6 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.five_conv = nn.ModuleList([\n",
    "        nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=1, groups=512),  # 3x3 Depthwise Conv\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=0)  # 1x1 Pointwise Conv\n",
    "            ) for _ in range(5)\n",
    "        ])\n",
    "\n",
    "        self.depthwise_conv7 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=1, groups=512)  # Depthwise convolution\n",
    "        self.pointwise_conv7 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.depthwise_conv8 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, groups=1024)\n",
    "        self.pointwise_conv8 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=1, stride=1, padding = 0)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=101)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = F.relu(self.depthwise_conv2(x))\n",
    "      x = F.relu(self.pointwise_conv2(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv3(x))\n",
    "      x = F.relu(self.pointwise_conv3(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv4(x))\n",
    "      x = F.relu(self.pointwise_conv4(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv5(x))\n",
    "      x = F.relu(self.pointwise_conv5(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv6(x))\n",
    "      x = F.relu(self.pointwise_conv6(x))\n",
    "\n",
    "      for conv in self.five_conv:\n",
    "            x = F.relu(conv(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv7(x))\n",
    "      x = F.relu(self.pointwise_conv7(x))\n",
    "\n",
    "      x = F.relu(self.depthwise_conv8(x))\n",
    "      x = F.relu(self.pointwise_conv8(x))\n",
    "\n",
    "      x = self.avg_pool(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.fc(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "cMbemwZvk12C"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_BELINCVoVaP"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork_2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "AIQcjn8oloT9"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Training loop\n",
    "def training():\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  train_labels = [label for _, label in train_dataset]\n",
    "  class_counts = Counter(train_labels)\n",
    "  total_samples = len(train_labels)\n",
    "  class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "  weight_tensor = torch.tensor([class_weights[i] for i in range(len(class_counts))], dtype=torch.float32)\n",
    "  weight_tensor = weight_tensor.to(device)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # Backward and optimize\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          if (i+1) % 100 == 0:\n",
    "              print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "  print(\"Training finished!\")\n",
    "\n",
    "  # Testing the model\n",
    "  model.eval() # Set the model to evaluation mode\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test accuracy of the model on the {total} test images: {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nV35iTUOnnPc",
    "outputId": "51d2bc58-fa21-4be2-b1c9-3f3a56af5827"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 101/163 [00:09<00:05, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/163], Loss: 4.6445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.56it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/163], Loss: 4.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00, 10.08it/s]\n",
      " 61%|██████▏   | 100/163 [00:09<00:06, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/163], Loss: 4.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.53it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/163], Loss: 4.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.64it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:06, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/163], Loss: 4.6141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.72it/s]\n",
      " 62%|██████▏   | 101/163 [00:09<00:06, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/163], Loss: 4.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:16<00:00, 10.10it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/163], Loss: 4.6199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.63it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:07,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/163], Loss: 4.6214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.66it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/163], Loss: 4.6164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.68it/s]\n",
      " 63%|██████▎   | 102/163 [00:09<00:05, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/163], Loss: 4.6096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:15<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!\n",
      "Test accuracy of the model on the 1736 test images: 0.055299539170506916\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
